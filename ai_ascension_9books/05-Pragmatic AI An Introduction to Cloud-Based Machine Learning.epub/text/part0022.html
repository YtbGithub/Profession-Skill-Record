<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:ns="http://www.w3.org/2001/10/synthesis" xml:lang="en-us" lang="en-us">
  <head>
    <title>11 Production AI for User-Generated Content</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<h2 class="h1" id="ch11"><span epub:type="pagebreak" id="page_195" class="calibre2"></span>11</h2>
<h2 class="h2a">Production AI for User-Generated Content</h2>
<p class="blockquote"><em class="calibre5">The man who can drive himself further once the effort gets painful is the man who will win.</em></p>
<p class="attribution">Roger Bannister</p>
<p class="noindent">What do Russian trolls, Facebook, and U.S. elections have to do with ML? Recommendation engines are at the heart of the central feedback loop of social networks and the user-generated content (UGC) they create. Users join the network and are recommended users and content with which to engage. Recommendation engines can be gamed because they amplify the effects of thought bubbles. The 2016 U.S. presidential election showed how important it is to understand how recommendation engines work and the limitations and strengths they offer.</p>
<p class="noindent">AI-based systems aren’t a panacea that only creates good things; rather, they offer a set of capabilities. It can be incredibly useful to get an appropriate product recommendation on a shopping site, but it can be equally frustrating to get recommended content that later turns out to be fake (perhaps generated by a foreign power motivated to sow discord in your country).</p>
<p class="noindent">This chapter covers recommendation engines and natural-language processing (NLP), both from a high level and a coding level. It also gives examples of how to use frameworks, such as the Python-based recommendation engine, Surprise, as well as instructions how to build your own. Some of the topics covered including the Netflix prize, singular-value decomposition (SVD), collaborative filtering, real-world problems with recommendation engines, NLP, and production sentiment analysis using cloud APIs.</p>
<h3 id="ch11lev1" class="calibre12"><span epub:type="pagebreak" id="page_196" class="calibre2"></span>The Netflix Prize Wasn’t Implemented in Production</h3>
<p class="noindent">Before “data science” was a common term and Kaggle was around, the Netflix prize caught the world by storm. The Netflix prize was a contest created to improve the recommendation of new movies. Many of the original ideas from the contest later turned into inspiration for other companies and products. Creating a $1 million data science contest back in 2006 sparked excitement that would foreshadow the current age of AI. In 2006, ironically, the age of cloud computing also began, with the launch of Amazon EC2.</p>
<p class="noindent">The cloud and the dawn of widespread AI have been intertwined. Netflix also has been one of the biggest users of the public cloud via AWS. Despite all these interesting historical footnotes, the Netflix prize-winning algorithm was never implemented into production. The winners in 2009, the “BellKor’s Pragmatic Chaos” team, achieved a greater than 10-percent improvement with a Test RMS of 0.867 (<a href="https://netflixprize.com/index.html" class="calibre7">https://netflixprize.com/index.html</a>). The team’s paper (<a href="https://www.netflixprize.com/assets/ProgressPrize2008_BellKor.pdf" class="calibre7">https://www.netflixprize.com/assets/ProgressPrize2008_BellKor.pdf</a>) describes that the solution is a linear blend of over 100 results. A quote in the paper that is particularly relevant is “A lesson here is that having lots of models is useful for the incremental results needed to win competitions, but practically, excellent systems can be built with just a few well-selected models.”</p>
<p class="noindent">The winning approach for the Netflix competition was not implemented in production at Netflix because the engineering complexity was deemed too great when compared with the gains produced. A core algorithm used in recommendations, SVD, as noted in “Fast SVD for Large-Scale Matrices” (<a href="http://sysrun.haifa.il.ibm.com/hrl/bigml/files/Holmes.pdf" class="calibre7">http://sysrun.haifa.il.ibm.com/hrl/bigml/files/Holmes.pdf</a>), “though feasible for small datasets or offline processing, many modern applications involve real-time learning and/or massive dataset dimensionality and size.” In practice, this is one of huge challenges of production ML—the time and computational resources necessary to produce results.</p>
<p class="noindent">I had a similar experience building recommendation engines at companies. When an algorithm is run in a batch manner, and it is simple, it can generate useful recommendations. But if a more complex approach is taken, or if the requirements go from batch to real time, the complexity of putting it into production and/or maintaining it explodes. The lesson here is that simpler is better: choosing to do batch-based ML versus real-time. Or choosing a simple model versus an ensemble of multiple techniques. Also, deciding whether it may make sense to call a recommendation engine API versus creating the solution yourself.</p>
<h3 id="ch11lev2" class="calibre12">Key Concepts in Recommendation Systems</h3>
<p class="noindent"><a href="part0022.html#ch11fig1" class="calibre7">Figure 11.1</a> shows a social network recommendation feedback loop. The more users a system has, the more content it creates. The more content that is created, the more recommendations it creates for new content. This feedback loop, in turn, drives more users and more content. As mentioned at the beginning of this chapter, these capabilities can be used for both positive and negative features of a platform.</p>
<div class="figure">
<div class="image1"><span epub:type="pagebreak" id="page_197"></span><a id="ch11fig1" class="calibre7"></a><img src="../images/00059.jpeg" alt="A figure depicts the Social network recommendation feedback loop. The recommendation engine feedback loop is consists of Users at the top-left, Content at the top-right, and Social Network at the bottom are connected in a closed loop." class="calibre8"/></div>
<p class="fig_caption"><span class="calibre6">Figure 11.1</span> Social Network Recommendation Feedback Loop</p>
</div>
<h3 id="ch11lev3" class="calibre12">Using the Surprise Framework in Python</h3>
<p class="noindent">One way to explore the concepts behind recommendation engines is to use the Surprise framework (<a href="http://surpriselib.com/" class="calibre7">http://surpriselib.com/</a>). A few of the handy things about the framework are that it has built-in data sets: MovieLens (<a href="https://grouplens.org/datasets/movielens/" class="calibre7">https://grouplens.org/datasets/movielens/</a>) and Jester, and it includes SVD and other common algorithms including similarity measures. It also includes tools to evaluate the performance of recommendations in the form of root mean squared error (RMSE) and mean absolute error (MAE), as well as the time it took to train the model.</p>
<p class="noindent">Here is an example of how it can be used in a pseudo production situation by tweaking one of the provided examples.</p>
<p class="noindent">First are the necessary imports to get the library loaded.</p>
<p class="codelink"><a id="p197pro01" href="part0040_split_000.html#p197pro01a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [2]: import io  <br class="calibre9"/>
   ...: from surprise import KNNBaseline<br class="calibre9"/>
   ...: from surprise import Dataset<br class="calibre9"/>
   ...: from surprise import get_dataset_dir<br class="calibre9"/>
   ...: import pandas as pd</p>
<p class="noindent">A helper function is created to convert IDs to names.</p>
<p class="codelink"><a id="p197pro02" href="part0040_split_001.html#p197pro02a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [3]: def read_item_names():<br class="calibre9"/>
   ...:     """Read the u.item file from MovieLens<br class="calibre9"/>
        100-k dataset and return two<br class="calibre9"/>
   ...:     mappings to convert raw ids<br class="calibre9"/>
        into movie names and movie names into raw ids.<br class="calibre9"/>
   ...:     """<br class="calibre9"/>
   ...:<br class="calibre9"/>
   ...:     file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'<br class="calibre9"/>
   ...:     rid_to_name = {}<br class="calibre9"/>
   ...:     name_to_rid = {}<br class="calibre9"/>
   ...:     with io.open(file_name, 'r', encoding='ISO-8859-1') as f:<br class="calibre9"/>
   ...:         for line in f:<br class="calibre9"/>
   ...:             line = line.split('|')<br class="calibre9"/>
   ...:             rid_to_name[line[0]] = line[1]<br class="calibre9"/>
   ...:             name_to_rid[line[1]] = line[0]<br class="calibre9"/>
   ...:<br class="calibre9"/>
   ...:     return rid_to_name, name_to_rid</p>
<p class="noindent"><span epub:type="pagebreak" id="page_198"></span>Similarities are computed between items.</p>
<p class="codelink"><a id="p198pro01" href="part0040_split_002.html#p198pro01a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [4]: # First, train the algorithm<br class="calibre9"/>
        # to compute the similarities between items<br class="calibre9"/>
   ...: data = Dataset.load_builtin('ml-100k')<br class="calibre9"/>
   ...: trainset = data.build_full_trainset()<br class="calibre9"/>
   ...: sim_options = {'name': 'pearson_baseline',<br class="calibre9"/>
         'user_based': False}<br class="calibre9"/>
   ...: algo = KNNBaseline(sim_options=sim_options)<br class="calibre9"/>
   ...: algo.fit(trainset)<br class="calibre9"/>
   ...:<br class="calibre9"/>
   ...:<br class="calibre9"/>
Estimating biases using als...<br class="calibre9"/>
Computing the pearson_baseline similarity matrix...<br class="calibre9"/>
Done computing similarity matrix.<br class="calibre9"/>
Out[4]: &lt;surprise.prediction_algorithms.knns.KNNBaseline&gt;</p>
<p class="noindent">Finally, “10 recommendations” are provided, which are similar to another example in this chapter.</p>
<p class="codelink"><a id="p198pro02" href="part0040_split_003.html#p198pro02a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [5]: # Read the mappings raw id &lt;-&gt; movie name<br class="calibre9"/>
   ...: rid_to_name, name_to_rid = read_item_names()<br class="calibre9"/>
   ...:<br class="calibre9"/>
   ...: # Retrieve inner id of the movie Toy Story<br class="calibre9"/>
   ...: toy_story_raw_id = name_to_rid['Toy Story (1995)']<br class="calibre9"/>
   ...: toy_story_inner_id = algo.trainset.to_inner_iid(<br class="calibre9"/>
        toy_story_raw_id)<br class="calibre9"/>
   ...:<br class="calibre9"/>
   ...: # Retrieve inner ids of the nearest neighbors of Toy Story.<br class="calibre9"/>
   ...: toy_story_neighbors = algo.get_neighbors(<br class="calibre9"/>
        toy_story_inner_id, k=10)<br class="calibre9"/>
   ...:<br class="calibre9"/>
   ...: # Convert inner ids of the neighbors into names.<br class="calibre9"/>
   ...: toy_story_neighbors = (algo.trainset.to_raw_iid(inner_id)<br class="calibre9"/>
   ...:                        for inner_id in toy_story_neighbors)<br class="calibre9"/>
   ...: toy_story_neighbors = (rid_to_name[rid]<br class="calibre9"/>
   ...:                        for rid in toy_story_neighbors)<br class="calibre9"/>
   ...:<br class="calibre9"/>
   ...: print('The 10 nearest neighbors of Toy Story are:')<br class="calibre9"/>
   ...: for movie in toy_story_neighbors:<br class="calibre9"/>
   ...:     print(movie)<br class="calibre9"/>
   ...:    <br class="calibre9"/>
The 10 nearest neighbors of Toy Story are:<br class="calibre9"/>
Beauty and the Beast (1991)<br class="calibre9"/>
Raiders of the Lost Ark (1981)<br class="calibre9"/>
That Thing You Do! (1996)<br class="calibre9"/>
Lion King, The (1994)<br class="calibre9"/>
Craft, The (1996)<br class="calibre9"/>
Liar Liar (1997)<br class="calibre9"/>
Aladdin (1992)<br class="calibre9"/>
Cool Hand Luke (1967)<br class="calibre9"/>
Winnie the Pooh and the Blustery Day (1968)<br class="calibre9"/>
Indiana Jones and the Last Crusade (1989)<br class="calibre9"/>
</p>
<p class="noindent"><span epub:type="pagebreak" id="page_199"></span>In exploring this example, consider the real-world issues with implementing this in production. Here is an example of a pseudocode API function that someone in your company may be asked to produce.</p>
<p class="codelink"><a id="p199pro01" href="part0040_split_004.html#p199pro01a" class="calibre7">Click here to view code image</a></p>
<p class="pre">def recommendations(movies, rec_count):<br class="calibre9"/>
    """Your<br class="calibre9"/>
    return recommendations"""<br class="calibre9"/>
<br class="calibre9"/>
movies = ["Beauty and the Beast (1991)", "Cool Hand Luke (1967)",.. ]<br class="calibre9"/>
<br class="calibre9"/>
print(recommendations(movies=movies, rec_count=10))</p>
<p class="noindent">Some questions to ask in implementing this are: What tradeoffs are you making in picking the top from a group of selections versus just a movie? How well will this algorithm perform on a very large data set? There are no right answers, but these are things you should think about as you deploy recommendation engines into production.</p>
<h3 id="ch11lev4" class="calibre12">Cloud Solutions to Recommendation Systems</h3>
<p class="noindent">The Google Cloud Platform has an example of using ML on Compute Engine to make product  recommendations (<a href="https://cloud.google.com/solutions/recommendations-using-machine-learning-on-compute-engine" class="calibre7">https://cloud.google.com/solutions/recommendations-using-machine-learning-on-compute-engine</a>) that is worth exploring. In the example, PySpark and the ALS  algorithm are used along with proprietary cloud SQL. Amazon also has an example of how to  build a recommendation engine using their platform, Spark and Elastic Map Reduce (EMR)  (<a href="https://aws.amazon.com/blogs/big-data/building-a-recommendation-engine-with-spark-ml-on-amazon-emr-using-zeppelin/" class="calibre7">https://aws.amazon.com/blogs/big-data/building-a-recommendation-engine-with-spark-ml-on-amazon-emr-using-zeppelin/</a>).</p>
<p class="noindent">In both cases, Spark is used to increase the performance of the algorithm by dividing the computation across a cluster of machines. Finally, AWS is heavily pushing SageMaker (<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html" class="calibre7">https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html</a>), which can do distributed Spark jobs natively or talk to an EMR cluster.</p>
<h3 id="ch11lev5" class="calibre12"><span epub:type="pagebreak" id="page_200" class="calibre2"></span>Real-World Production Issues with Recommendations</h3>
<p class="noindent">Most books and articles on recommendation focus purely on the technical aspects of recommendation systems. This book is about pragmatism, and so there are some issues to talk about when it comes to recommendation systems. A few of these topics are covered in this section: performance, ETL, user experience (UX), and shills/bots.</p>
<p class="noindent">One of the most popular algorithms as discussed is O(n_samples^2 * n_features) or quadratic. This means that it is very difficult to train a model in real time and get an optimum solution. Therefore, training a recommendation system will need to occur as a batch job in most cases, without some tricks like using a greedy heuristic and/or only creating a small subset of recommendations for active users, popular products, etc.</p>
<p class="noindent">When I created a user follow recommendation system from scratch for a social network, I found many of these issues came front and center. Training the model took hours, so the only realistic solution was to run it nightly. Additionally, I later created an in-memory copy of our training data, so the algorithm was only bound on CPU, not I/O.</p>
<p class="noindent">Performance is a nontrivial concern in creating a production recommendation system in both the short term and the long term. It is possible that the approach you initially use may not scale as your company grows users and products. Perhaps initially, a Jupyter Notebook, Pandas, and scikit-learn were acceptable when you had 10,000 users on your platform, but it may turn out quickly to not be a scalable solution.</p>
<p class="noindent">Instead, a PySpark-based support vector machine training algorithm (<a href="http://spark.apache.org/docs/2.1.0/api/python/pyspark.mllib.html" class="calibre7">http://spark.apache.org/docs/2.1.0/api/python/pyspark.mllib.html</a>) may dramatically improve performance and decrease maintenance time. And then later, again, you may need to switch to dedicated ML chips like TPU or the NVIDIA Volta. Having the ability to plan for this capacity while still making initial working solutions is a critical skill to have to implement pragmatic AI solutions that actually make it to production.</p>
<h4 id="ch11lev5sub1" class="calibre16">Real-World Recommendation Problems: Integration with Production APIs</h4>
<p class="noindent">I found many real-world problems surface in production in startups that build recommendations. These are problems that are not as heavily discussed in ML books. One such problem is the “cold-start problem.” In the examples using the Surprise framework, there is already a massive database of “correct answers.” In the real world, you have so few users or products it doesn’t make sense to train a model. What can you do?</p>
<p class="noindent">A decent solution is to make the path of the recommendation engine follow three phases. For phase one, take the most popular users, content, or products and serve those out as a recommendation. As more UGC is created on the platform, for phase two, use similarity scoring (without training a model). Here is some “hand-coded” code I have used in production a couple of different times that did just that. First we have a Tanimoto score, or Jaccard distance, by another name.</p>
<p class="codelink"><a id="p201pro01" href="part0040_split_005.html#p201pro01a" class="calibre7">Click here to view code image</a></p>
<p class="pre">"""Data Science Algorithms"""<br class="calibre9"/>
<br class="calibre9"/>
<br class="calibre9"/>
def tanimoto(list1, list2):<br class="calibre9"/>
    """tanimoto coefficient<br class="calibre9"/>
<br class="calibre9"/>
    In [2]: list2=['39229', '31995', '32015']<br class="calibre9"/>
    In [3]: list1=['31936', '35989', '27489',<br class="calibre9"/>
        '39229', '15468', '31993', '26478']<br class="calibre9"/>
    In [4]: tanimoto(list1,list2)<br class="calibre9"/>
    Out[4]: 0.1111111111111111<br class="calibre9"/>
<br class="calibre9"/>
    Uses intersection of two sets to determine numerical score<br class="calibre9"/>
<br class="calibre9"/>
    """<br class="calibre9"/>
<br class="calibre9"/>
    intersection = set(list1).intersection(set(list2))<br class="calibre9"/>
    return float(len(intersection))/(len(list1)) +\<br class="calibre9"/>
         len(list2) - len(intersection)</p>
<p class="noindent"><span epub:type="pagebreak" id="page_201"></span>Next is HBD: Here Be Dragons. Follower relationships are downloaded and converted in a Pandas DataFrame.</p>
<p class="codelink"><a id="p201pro02" href="part0040_split_006.html#p201pro02a" class="calibre7">Click here to view code image</a></p>
<p class="pre">import os<br class="calibre9"/>
import pandas as pd<br class="calibre9"/>
<br class="calibre9"/>
from .algorithms import tanimoto<br class="calibre9"/>
<br class="calibre9"/>
def follows_dataframe(path=None):<br class="calibre9"/>
    """Creates Follows Dataframe"""<br class="calibre9"/>
<br class="calibre9"/>
    if not path:<br class="calibre9"/>
        path = os.path.join(os.getenv('PYTHONPATH'),<br class="calibre9"/>
          'ext', 'follows.csv')<br class="calibre9"/>
<br class="calibre9"/>
    df = pd.read_csv(path)<br class="calibre9"/>
    return df<br class="calibre9"/>
<br class="calibre9"/>
def follower_statistics(df):<br class="calibre9"/>
    """Returns counts of follower behavior<br class="calibre9"/>
<br class="calibre9"/>
    In [15]: follow_counts.head()<br class="calibre9"/>
        Out[15]:<br class="calibre9"/>
        followerId<br class="calibre9"/>
        581bea20-962c-11e5-8c10-0242528e2f1b    1558<br class="calibre9"/>
        74d96701-e82b-11e4-b88d-068394965ab2      94<br class="calibre9"/>
        d3ea2a10-e81a-11e4-9090-0242528e2f1b      93<br class="calibre9"/>
        0ed9aef0-f029-11e4-82f0-0aa89fecadc2      88<br class="calibre9"/>
        55d31000-1b74-11e5-b730-0680a328ea36      64<br class="calibre9"/>
        Name: followingId, dtype: int64<br class="calibre9"/>
<br class="calibre9"/>
    """<br class="calibre9"/>
<br class="calibre9"/>
<span epub:type="pagebreak" id="page_202"></span>
    follow_counts = df.groupby(['followerId'])['followingId'].\<br class="calibre9"/>
        count().sort_values(ascending=False)<br class="calibre9"/>
    return follow_counts<br class="calibre9"/>
<br class="calibre9"/>
def follow_metadata_statistics(df):<br class="calibre9"/>
    """Generates metadata about follower behavior<br class="calibre9"/>
    <br class="calibre9"/>
    In [13]: df_metadata.describe()<br class="calibre9"/>
        Out[13]:<br class="calibre9"/>
        count    2145.000000<br class="calibre9"/>
        mean        3.276923<br class="calibre9"/>
        std        33.961413<br class="calibre9"/>
        min         1.000000<br class="calibre9"/>
        25%         1.000000<br class="calibre9"/>
        50%         1.000000<br class="calibre9"/>
        75%         3.000000<br class="calibre9"/>
        max      1558.000000<br class="calibre9"/>
        Name: followingId, dtype: float64<br class="calibre9"/>
<br class="calibre9"/>
    """<br class="calibre9"/>
<br class="calibre9"/>
    dfs = follower_statistics(df)<br class="calibre9"/>
    df_metadata = dfs.describe()<br class="calibre9"/>
    return df_metadata<br class="calibre9"/>
<br class="calibre9"/>
def follow_relations_df(df):<br class="calibre9"/>
    """Returns a dataframe of follower with all relations"""<br class="calibre9"/>
<br class="calibre9"/>
    df = df.groupby('followerId').followingId.apply(list)<br class="calibre9"/>
    dfr = df.to_frame("follow_relations")<br class="calibre9"/>
    dfr.reset_index(level=0, inplace=True)<br class="calibre9"/>
    return dfr<br class="calibre9"/>
<br class="calibre9"/>
def simple_score(column, followers):<br class="calibre9"/>
    """Used as an apply function for dataframe"""<br class="calibre9"/>
<br class="calibre9"/>
    return tanimoto(column,followers)<br class="calibre9"/>
<br class="calibre9"/>
def get_followers_by_id(dfr, followerId):<br class="calibre9"/>
    """Returns a list of followers by followerID"""<br class="calibre9"/>
<br class="calibre9"/>
    followers = dfr.loc[dfr['followerId'] == followerId]<br class="calibre9"/>
    fr = followers['follow_relations']<br class="calibre9"/>
    return fr.tolist()[0]<br class="calibre9"/>
<br class="calibre9"/>
def generate_similarity_scores(dfr, followerId,<br class="calibre9"/>
          limit=10, threshold=.1):<br class="calibre9"/>
    """Generates a list of recommendations for a followerID"""<br class="calibre9"/>
<br class="calibre9"/>
    followers = get_followers_by_id(dfr, followerId)<br class="calibre9"/>
    recs = dfr['follow_relations'].\<br class="calibre9"/>
        apply(simple_score, args=(followers,)).\<br class="calibre9"/>
            where(dfr&gt;threshold).dropna().sort_values()[-limit:]<br class="calibre9"/>
    filters_recs = recs.where(recs&gt;threshold)<br class="calibre9"/>
    return filters_recs<br class="calibre9"/>
<br class="calibre9"/>
def return_similarity_scores_with_ids(dfr, scores):<br class="calibre9"/>
    """Returns Scores and FollowerID"""<br class="calibre9"/>
<br class="calibre9"/>
    dfs = pd.DataFrame(dfr, index=scores.index.tolist())<br class="calibre9"/>
    dfs['scores'] = scores[dfs.index]<br class="calibre9"/>
    dfs['following_count'] = dfs['follow_relations'].apply(len)<br class="calibre9"/>
    return dfs</p>
<p class="noindent"><span epub:type="pagebreak" id="page_203"></span>To use this API, you would engage with it by following this sequence.</p>
<p class="codelink"><a id="p203pro01" href="part0040_split_009.html#p203pro01a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [1]: follows import *<br class="calibre9"/>
<br class="calibre9"/>
In [2]: df = follows_dataframe()<br class="calibre9"/>
<br class="calibre9"/>
In [3]: dfr = follow_relations_df(df)<br class="calibre9"/>
<br class="calibre9"/>
In [4]: dfr.head()<br class="calibre9"/>
<br class="calibre9"/>
In [5]: scores = generate_similarity_scores(dfr,<br class="calibre9"/>
         "00480160-0e6a-11e6-b5a1-06f8ea4c790f")<br class="calibre9"/>
<br class="calibre9"/>
In [5]: scores<br class="calibre9"/>
Out[5]:<br class="calibre9"/>
2144    0.000000<br class="calibre9"/>
713     0.000000<br class="calibre9"/>
714     0.000000<br class="calibre9"/>
715     0.000000<br class="calibre9"/>
716     0.000000<br class="calibre9"/>
717     0.000000<br class="calibre9"/>
712     0.000000<br class="calibre9"/>
980     0.333333<br class="calibre9"/>
2057    0.333333<br class="calibre9"/>
3       1.000000<br class="calibre9"/>
Name: follow_relations, dtype: float64<br class="calibre9"/>
<br class="calibre9"/>
In [6]: dfs = return_similarity_scores_with_ids(dfr, scores)<br class="calibre9"/>
<br class="calibre9"/>
In [6]: dfs<br class="calibre9"/>
Out[6]:<br class="calibre9"/>
                                followerId  \<br class="calibre9"/>
980   76cce300-0e6a-11e6-83e2-0242528e2f1b  <br class="calibre9"/>
2057  f5ccbf50-0e69-11e6-b5a1-06f8ea4c790f  <br class="calibre9"/>
3     00480160-0e6a-11e6-b5a1-06f8ea4c790f  <br class="calibre9"/>
<br class="calibre9"/>
                                       follow_relations    scores  \<br class="calibre9"/>
980   [f5ccbf50-0e69-11e6-b5a1-06f8ea4c790f, 0048016...  0.333333  <br class="calibre9"/>
2057  [76cce300-0e6a-11e6-83e2-0242528e2f1b, 0048016...  0.333333  <br class="calibre9"/>
3     [f5ccbf50-0e69-11e6-b5a1-06f8ea4c790f, 76cce30...         1  <br class="calibre9"/>
<br class="calibre9"/>
      following_count  <br class="calibre9"/>
980                 2  <br class="calibre9"/>
2057                2  <br class="calibre9"/>
3                   2</p>
<p class="noindent"><span epub:type="pagebreak" id="page_204"></span>This “phase 2” similarity score-based recommendation with the current implementation  would need to be run as a batch API. Additionally, Pandas will eventually run into some  performance problems at scale. Ditching it at some point for either PySpark or Pandas on Ray (<a href="https://rise.cs.berkeley.edu/blog/pandas-on-ray/?twitter=@bigdata" class="calibre7">https://rise.cs.berkeley.edu/blog/pandas-on-ray/?twitter=@bigdata</a>) is going to be a good move.</p>
<p class="noindent">For “phase 3,” it is finally time to pull out the big guns and use something like Surprise and/or  PySpark to train an SVD-based model and figure out model accuracy. In the first part of your company’s history, though, why bother when there is little to no value in doing formal ML model training?</p>
<p class="noindent">Another production API issue is how to deal with rejected recommendations. There is nothing more irritating to a user than to keep getting recommendations for things you don’t want or already have. So, yet another sticky production issue needs to be solved. Ideally, the user is given the ability to click, “do not show again” for a list of recommendations, or quickly your recommendation engine becomes garbage. Additionally, the user is telling you something, so why not take that signal and feed it back into your recommendation engine model?</p>
<h3 id="ch11lev6" class="calibre12">Cloud NLP and Sentiment Analysis</h3>
<p class="noindent">All three of the dominant cloud providers—AWS, GCP, and Azure—have solid NLP engines that can be called via an API. In this section, NLP examples on all three clouds will be explored. Additionally, a real-world production AI pipeline for NLP pipeline will be created on AWS using serverless technology.</p>
<h3 id="ch11lev7" class="calibre12">NLP on Azure</h3>
<p class="noindent">Microsoft Cognitive Services have a Text Analytics API that has language detection, key phrase extraction, and sentiment analysis. In <a href="part0022.html#ch11fig2" class="calibre7">Figure 11.2</a>, the endpoint is created so API calls can be made. This example will take a negative collection of movie reviews from the Cornell Computer Science Data Set on Movie Reviews (<a href="http://www.cs.cornell.edu/people/pabo/movie-review-data/" class="calibre7">http://www.cs.cornell.edu/people/pabo/movie-review-data/</a>) and use it to walk through the API.</p>
<div class="figure">
<div class="image"><span epub:type="pagebreak" id="page_205"></span><a id="ch11fig2" class="calibre7"></a><img src="../images/00060.jpeg" aria-describedby="alt_11fig02" alt="A screenshot of &quot;MovieRevieSentimentAnalysis - Quick start&quot; is displayed." class="calibre8"/>
<aside class="hidden" id="alt_11fig02" data-AmznRemoved-M8="true" data-AmznRemoved="mobi7">
<p class="calibre21">The Quick start is selected under the Resource management on the left pane. In the content pane, the Quickstart guidance to get up and running with Test Analysis API with four instructions. 1. Grab your keys, 2. Make an API call to endpoint https://eastus.api.cognitive.microsoft.com/text/analytics/v2.0, 3. Enjoy coding, and 4. Additional resources.</p>
</aside>
</div>
<p class="fig_caption"><span class="calibre6">Figure 11.2</span> Microsoft Azure Cognitive Services API</p>
</div>
<p class="noindent"><span epub:type="pagebreak" id="page_206"></span>First, imports are done in this first block in Jupyter Notebook.</p>
<p class="codelink"><a id="p206pro01" href="part0040_split_011.html#p206pro01a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [1]: import requests<br class="calibre9"/>
   ...: import os<br class="calibre9"/>
   ...: import pandas as pd<br class="calibre9"/>
   ...: import seaborn as sns<br class="calibre9"/>
   ...: import matplotlib as plt<br class="calibre9"/>
   ...:</p>
<p class="noindent">Next, an API key is taken from the environment. This API key was fetched from the console shown in <a href="part0022.html#ch11fig2" class="calibre7">Figure 11.2</a> under the section keys and was exported as an environmental variable, so it isn’t hard-coded into code. Additionally, the text API URL that will be used later is assigned to a variable.</p>
<p class="codelink"><a id="p206pro02" href="part0040_split_012.html#p206pro02a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [4]: subscription_key=os.environ.get("AZURE_API_KEY")<br class="calibre9"/>
In [5]: text_analytics_base_url =\<br class="calibre9"/>
   ...: https://eastus.api.cognitive.microsoft.com/\<br class="calibre9"/>
        text/analytics/v2.0/</p>
<p class="noindent">Next, one of the negative reviews is formatted in the way the API expects.</p>
<p class="codelink"><a id="p206pro03" href="part0040_split_013.html#p206pro03a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [9]: documents = {"documents":[]}<br class="calibre9"/>
   ...: path = "../data/review_polarity/\<br class="calibre9"/>
        txt_sentoken/neg/cv000_29416.txt"<br class="calibre9"/>
   ...: doc1 = open(path, "r")<br class="calibre9"/>
   ...: output = doc1.readlines()<br class="calibre9"/>
   ...: count = 0<br class="calibre9"/>
   ...: for line in output:<br class="calibre9"/>
   ...:     count +=1<br class="calibre9"/>
   ...:     record = {"id": count, "language": "en", "text": line}<br class="calibre9"/>
   ...:     documents["documents"].append(record)<br class="calibre9"/>
   ...:<br class="calibre9"/>
   ...: #print it out<br class="calibre9"/>
   ...: documents</p>
<p class="noindent">The data structure with the following shape is created.</p>
<p class="codelink"><a id="p206pro04" href="part0040_split_014.html#p206pro04a" class="calibre7">Click here to view code image</a></p>
<p class="pre">Out[9]:<br class="calibre9"/>
{'documents': [{'id': 1,<br class="calibre9"/>
   'language': 'en',<br class="calibre9"/>
   'text': 'plot : two teen couples go to a\<br class="calibre9"/>
         church party , drink and then drive . \n'},<br class="calibre9"/>
  {'id': 2, 'language': 'en',<br class="calibre9"/>
 'text': 'they get into an accident . \n'},<br class="calibre9"/>
  {'id': 3,<br class="calibre9"/>
   'language': 'en',<br class="calibre9"/>
   'text': 'one of the guys dies ,\<br class="calibre9"/>
 but his girlfriend continues to see him in her life,\<br class="calibre9"/>
 and has nightmares . \n'},<br class="calibre9"/>
  {'id': 4, 'language': 'en', 'text': "what's the deal ? \n"},<br class="calibre9"/>
  {'id': 5,<br class="calibre9"/>
   'language': 'en',</p>
<p class="noindent"><span epub:type="pagebreak" id="page_207"></span>Finally, the sentiment analysis API is used to score the individual documents.</p>
<p class="codelink"><a id="p207pro01" href="part0040_split_015.html#p207pro01a" class="calibre7">Click here to view code image</a></p>
<p class="pre">{'documents': [{'id': '1', 'score': 0.5},<br class="calibre9"/>
  {'id': '2', 'score': 0.13049307465553284},<br class="calibre9"/>
  {'id': '3', 'score': 0.09667149186134338},<br class="calibre9"/>
  {'id': '4', 'score': 0.8442018032073975},<br class="calibre9"/>
  {'id': '5', 'score': 0.808459997177124</p>
<p class="noindent">At this point, the return scores can be converted into a Pandas DataFrame to do some EDA. It isn’t a surprise that the median value of the sentiments for a negative review are 0.23 on a scale of 0 to 1, where 1 is extremely positive and 0 is extremely negative.</p>
<p class="codelink"><a id="p207pro02" href="part0040_split_016.html#p207pro02a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [11]: df = pd.DataFrame(sentiments['documents'])<br class="calibre9"/>
<br class="calibre9"/>
In [12]: df.describe()<br class="calibre9"/>
Out[12]:<br class="calibre9"/>
           score<br class="calibre9"/>
count  35.000000<br class="calibre9"/>
mean    0.439081<br class="calibre9"/>
std     0.316936<br class="calibre9"/>
min     0.037574<br class="calibre9"/>
25%     0.159229<br class="calibre9"/>
50%     0.233703<br class="calibre9"/>
75%     0.803651<br class="calibre9"/>
max     0.948562</p>
<p class="noindent">This is further explained by doing a density plot. <a href="part0022.html#ch11fig3" class="calibre7">Figure 11.3</a> shows a majority of highly negative sentiments.</p>
<div class="figure">
<div class="image"><a id="ch11fig3" class="calibre7"></a><img src="../images/00061.jpeg" aria-describedby="alt_11fig03" alt="A screenshot explains the majority of highly negative sentiments are found using a density plot." class="calibre8"/>
<aside class="hidden" id="alt_11fig03" data-AmznRemoved-M8="true" data-AmznRemoved="mobi7">
<p class="calibre21">In the screenshot, the text reads: In [37]: sns . kdeplot (df [ 'score'], shade=True) Out [37]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x11ab9e780&gt; The graph is shown below with the horizontal axis ranges from negative 0.50 to 1.50, in increments of 0.25 and the vertical axis ranges from 0.0 to 1.2, in increments of 0.2. The graph shows two bumps touching the horizontal axis.</p>
</aside>
</div>
<p class="fig_caption"><span class="calibre6">Figure 11.3</span> Density Plot of Sentiment Scores</p>
</div>
<h3 id="ch11lev8" class="calibre12"><span epub:type="pagebreak" id="page_208" class="calibre2"></span>NLP on GCP</h3>
<p class="noindent">There is a lot to like about the Google Cloud Natural Language API (<a href="https://cloud.google.com/natural-language/docs/how-to" class="calibre7">https://cloud.google.com/natural-language/docs/how-to</a>). One of the convenient features of the API is that you can use it in two different ways: analyzing sentiment in a string, and also analyzing sentiment from Google Cloud Storage. Google Cloud also has a tremendously powerful command-line tool that makes it easy to explore their API. Finally, it has some fascinating AI APIs, some of which will be explored in this chapter: analyzing sentiment, analyzing entities, analyzing syntax, analyzing entity  sentiment, and classifying content.</p>
<h3 id="ch11lev9" class="calibre12">Exploring the Entity API</h3>
<p class="noindent">Using the command-line gcloud API is a great way to explore what one of the APIs does. In the example, a phrase is sent via the command line about LeBron James and the Cleveland Cavaliers.</p>
<p class="codelink"><a id="p208pro01" href="part0040_split_017.html#p208pro01a" class="calibre7">Click here to view code image</a></p>
<p class="pre">→  gcloud ml language analyze-entities --content=\<br class="calibre9"/>
"LeBron James plays for the Cleveland Cavaliers."<br class="calibre9"/>
{<br class="calibre9"/>
  "entities": [<br class="calibre9"/>
    {<br class="calibre9"/>
      "mentions": [<br class="calibre9"/>
        {<br class="calibre9"/>
          "text": {<br class="calibre9"/>
            "beginOffset": 0,<br class="calibre9"/>
            "content": "LeBron James"<br class="calibre9"/>
          },<br class="calibre9"/>
          "type": "PROPER"<br class="calibre9"/>
        }<br class="calibre9"/>
      ],<br class="calibre9"/>
      "metadata": {<br class="calibre9"/>
        "mid": "/m/01jz6d",<br class="calibre9"/>
        "wikipedia_url": "https://en.wikipedia.org/wiki/LeBron_James"<br class="calibre9"/>
      },<br class="calibre9"/>
      "name": "LeBron James",<br class="calibre9"/>
      "salience": 0.8991045,<br class="calibre9"/>
      "type": "PERSON"<br class="calibre9"/>
    },<br class="calibre9"/>
    {<br class="calibre9"/>
      "mentions": [<br class="calibre9"/>
        {<br class="calibre9"/>
          "text": {<br class="calibre9"/>
            "beginOffset": 27,<br class="calibre9"/>
            "content": "Cleveland Cavaliers"<br class="calibre9"/>
          },<br class="calibre9"/>
          "type": "PROPER"<br class="calibre9"/>
        }<br class="calibre9"/>
      ],<br class="calibre9"/>
      "metadata": {<br class="calibre9"/>
        "mid": "/m/0jm7n",<br class="calibre9"/>
        "wikipedia_url": "https://en.wikipedia.org/\<br class="calibre9"/>
wiki/Cleveland_Cavaliers"<br class="calibre9"/>
      },<br class="calibre9"/>
      "name": "Cleveland Cavaliers",<br class="calibre9"/>
      "salience": 0.100895494,<br class="calibre9"/>
      "type": "ORGANIZATION"<br class="calibre9"/>
    }<br class="calibre9"/>
  ],<br class="calibre9"/>
  "language": "en"<br class="calibre9"/>
}</p>
<p class="noindent"><span epub:type="pagebreak" id="page_209"></span>A second way to explore the API is to use Python. To get an API key and authenticate, you need to follow the instructions (<a href="https://cloud.google.com/docs/authentication/getting-started" class="calibre7">https://cloud.google.com/docs/authentication/getting-started</a>). Then, launch the Jupyter Notebook in the same shell as the GOOGLE_APPLICATION_CREDENTIALS variable is exported:</p>
<p class="codelink"><a id="p209pro01" href="part0040_split_019.html#p209pro01a" class="calibre7">Click here to view code image</a></p>
<p class="pre">→  ✗ export GOOGLE_APPLICATION_CREDENTIALS=\<br class="calibre9"/>
        /Users/noahgift/cloudai-65b4e3299be1.json</p>
<p class="pre">→  ✗ jupyter notebook</p>
<p class="noindent">Once this authentication process is complete, the rest is straightforward. First, the python language api must be imported (This can be installed via pip if it isn’t already: <code class="calibre11">pip install --upgrade google-cloud-language.</code>)</p>
<p class="codelink"><a id="p209pro02" href="part0040_split_020.html#p209pro02a" class="calibre7">Click here to view code image</a></p>
<p class="pre"><br class="calibre9"/>
In [1]: # Imports the Google Cloud client library<br class="calibre9"/>
   ...: from google.cloud import language<br class="calibre9"/>
   ...: from google.cloud.language import enums<br class="calibre9"/>
   ...: from google.cloud.language import types</p>
<p class="noindent">Next, a phrase is sent to the API and entity metadata is returned with an analysis.</p>
<p class="codelink"><a id="p209pro03" href="part0040_split_021.html#p209pro03a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [2]: text = "LeBron James plays for the Cleveland Cavaliers."<br class="calibre9"/>
   ...: client = language.LanguageServiceClient()<br class="calibre9"/>
   ...: document = types.Document(<br class="calibre9"/>
   ...:         content=text,<br class="calibre9"/>
   ...:         type=enums.Document.Type.PLAIN_TEXT)<br class="calibre9"/>
   ...: entities = client.analyze_entities(document).entities<br class="calibre9"/>
   ...:</p>
<p class="noindent">The output has a similar look and feel to the command-line version, but it comes back as a Python list.</p>
<p class="codelink"><a id="p209pro04" href="part0040_split_022.html#p209pro04a" class="calibre7">Click here to view code image</a></p>
<p class="pre">[name: "LeBron James"<br class="calibre9"/>
type: PERSON<br class="calibre9"/>
metadata {<br class="calibre9"/>
  key: "mid"<br class="calibre9"/>
  value: "/m/01jz6d"<br class="calibre9"/>
}<br class="calibre9"/>
metadata {<br class="calibre9"/>
  key: "wikipedia_url"<br class="calibre9"/>
  value: "https://en.wikipedia.org/wiki/LeBron_James"<br class="calibre9"/>
}<br class="calibre9"/>
salience: 0.8991044759750366<br class="calibre9"/>
mentions {<br class="calibre9"/>
  text {<br class="calibre9"/>
    content: "LeBron James"<br class="calibre9"/>
    begin_offset: -1<br class="calibre9"/>
  }<br class="calibre9"/>
  type: PROPER<br class="calibre9"/>
}<br class="calibre9"/>
, name: "Cleveland Cavaliers"<br class="calibre9"/>
type: ORGANIZATION<br class="calibre9"/>
metadata {<br class="calibre9"/>
  key: "mid"<br class="calibre9"/>
  value: "/m/0jm7n"<br class="calibre9"/>
}<br class="calibre9"/>
metadata {<br class="calibre9"/>
  key: "wikipedia_url"<br class="calibre9"/>
  value: "https://en.wikipedia.org/wiki/Cleveland_Cavaliers"<br class="calibre9"/>
}<br class="calibre9"/>
salience: 0.10089549422264099<br class="calibre9"/>
mentions {<br class="calibre9"/>
  text {<br class="calibre9"/>
    content: "Cleveland Cavaliers"<br class="calibre9"/>
    begin_offset: -1<br class="calibre9"/>
  }<br class="calibre9"/>
  type: PROPER<br class="calibre9"/>
}<br class="calibre9"/>
]</p>
<p class="noindent"><span epub:type="pagebreak" id="page_210"></span>A few of the takeaways are that this API could be easily merged with some of the other explorations done in <a href="part0017.html#ch06" class="calibre7">Chapter 6</a>, “<a href="part0017.html#ch06" class="calibre7">Predicting Social-Media Influence in the NBA.</a>” It wouldn’t be hard to imagine creating an AI application that found extensive information about social influencers by using these NLP APIs as a starting point. Another takeaway is that the command line given to you by the GCP Cognitive APIs is quite powerful.</p>
<h3 id="ch11lev10" class="calibre12">Production Serverless AI Pipeline for NLP on AWS</h3>
<p class="noindent">One thing AWS does well, perhaps better than any of the “big three” clouds, is make it easy to create production applications that are easy to write and manage. One of their “game changer” innovations is AWS Lambda. It is available to both orchestrate pipelines and serve our HTTP endpoints, like in the case of chalice. In <a href="part0022.html#ch11fig4" class="calibre7">Figure 11.4</a>, a real-world production pipeline is described for creating an NLP pipeline.</p>
<div class="figure">
<div class="image"><span epub:type="pagebreak" id="page_211"></span><a id="ch11fig4" class="calibre7"></a><img src="../images/00062.jpeg" aria-describedby="alt_11fig04" alt="A figure depicts the process of production serverless NLP pipeline on AWS." class="calibre8"/>
<aside class="hidden" id="alt_11fig04" data-AmznRemoved-M8="true" data-AmznRemoved="mobi7">
<p class="calibre21">The S3 creates the S3 Creation Event that triggers NLP Scoring to AWS Batch. The AWS Batch is transferred to the AWS NLP Scoring. The Scores Written to Dynamo is sent from the AWS NLP Scoring to the AWS DynamoDB Table that is further sent to Chalice. The Chalice produces /content /&lt;id&gt;/ sentiment.</p>
</aside>
</div>
<p class="fig_caption"><span class="calibre6">Figure 11.4</span> Production Serverless NLP Pipeline on AWS</p>
</div>
<p class="noindent">To get started with AWS sentiment analysis, some libraries need to be imported.</p>
<p class="codelink"><a id="p211pro01" href="part0040_split_024.html#p211pro01a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [1]: import pandas as pd<br class="calibre9"/>
   ...: import boto3<br class="calibre9"/>
   ...: import json</p>
<p class="noindent">Next, a simple test is created.</p>
<p class="codelink"><a id="p211pro02" href="part0040_split_025.html#p211pro02a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [5]: comprehend = boto3.client(service_name='comprehend')<br class="calibre9"/>
   ...: text = "It is raining today in Seattle"<br class="calibre9"/>
   ...: print('Calling DetectSentiment')<br class="calibre9"/>
   ...: print(json.dumps(comprehend.detect_sentiment(\<br class="calibre9"/>
Text=text, LanguageCode='en'), sort_keys=True, indent=4))<br class="calibre9"/>
   ...:<br class="calibre9"/>
   ...: print('End of DetectSentiment\n')<br class="calibre9"/>
   ...:</p>
<p class="noindent">The output shows a “SentimentScore.”</p>
<p class="codelink"><a id="p211pro04" href="part0040_split_026.html#p211pro04a" class="calibre7">Click here to view code image</a></p>
<p class="pre">Calling DetectSentiment<br class="calibre9"/>
{<br class="calibre9"/>
    "ResponseMetadata": {<br class="calibre9"/>
        "HTTPHeaders": {<br class="calibre9"/>
            "connection": "keep-alive",<br class="calibre9"/>
            "content-length": "164",<br class="calibre9"/>
            "content-type": "application/x-amz-json-1.1",<br class="calibre9"/>
            "date": "Mon, 05 Mar 2018 05:38:53 GMT",<br class="calibre9"/>
            "x-amzn-requestid":\<br class="calibre9"/>
 "7d532149-2037-11e8-b422-3534e4f7cfa2"<br class="calibre9"/>
        },<br class="calibre9"/>
        "HTTPStatusCode": 200,<br class="calibre9"/>
        "RequestId": "7d532149-2037-11e8-b422-3534e4f7cfa2",<br class="calibre9"/>
        "RetryAttempts": 0<br class="calibre9"/>
    },<br class="calibre9"/>
    "Sentiment": "NEUTRAL",<br class="calibre9"/>
    "SentimentScore": {<br class="calibre9"/>
        "Mixed": 0.002063251566141844,<br class="calibre9"/>
        "Negative": 0.013271247036755085,<br class="calibre9"/>
        "Neutral": 0.9274052977561951,<br class="calibre9"/>
        "Positive": 0.057260122150182724<br class="calibre9"/>
    }<br class="calibre9"/>
}<br class="calibre9"/>
End of DetectSentiment</p>
<p class="noindent"><span epub:type="pagebreak" id="page_212"></span>Now, in a more realistic example, we’ll use the previous “negative movie reviews document” from the Azure example. The document is read in.</p>
<p class="codelink"><a id="p212pro01" href="part0040_split_027.html#p212pro01a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [6]: path = "/Users/noahgift/Desktop/review_polarity/\<br class="calibre9"/>
txt_sentoken/neg/cv000_29416.txt"<br class="calibre9"/>
   ...: doc1 = open(path, "r")<br class="calibre9"/>
   ...: output = doc1.readlines()<br class="calibre9"/>
   ...:</p>
<p class="noindent">Next, one of the “documents” (rember each line is a document according to NLP APIs) is scored.</p>
<p class="codelink"><a id="p212pro02" href="part0040_split_028.html#p212pro02a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [7]: print(json.dumps(comprehend.detect_sentiment(\<br class="calibre9"/>
Text=output[2], LanguageCode='en'), sort_keys=True, inden<br class="calibre9"/>
   ...: t=4))<br class="calibre9"/>
<br class="calibre9"/>
{<br class="calibre9"/>
    "ResponseMetadata": {<br class="calibre9"/>
        "HTTPHeaders": {<br class="calibre9"/>
            "connection": "keep-alive",<br class="calibre9"/>
            "content-length": "158",<br class="calibre9"/>
            "content-type": "application/x-amz-json-1.1",<br class="calibre9"/>
            "date": "Mon, 05 Mar 2018 05:43:25 GMT",<br class="calibre9"/>
            "x-amzn-requestid":\<br class="calibre9"/>
 "1fa0f6e8-2038-11e8-ae6f-9f137b5a61cb"<br class="calibre9"/>
        },<br class="calibre9"/>
        "HTTPStatusCode": 200,<br class="calibre9"/>
        "RequestId": "1fa0f6e8-2038-11e8-ae6f-9f137b5a61cb",<br class="calibre9"/>
        "RetryAttempts": 0<br class="calibre9"/>
    },<br class="calibre9"/>
    "Sentiment": "NEUTRAL",<br class="calibre9"/>
    "SentimentScore": {<br class="calibre9"/>
        "Mixed": 0.1490383893251419,<br class="calibre9"/>
        "Negative": 0.3341641128063202,<br class="calibre9"/>
        "Neutral": 0.468740850687027,<br class="calibre9"/>
        "Positive": 0.04805663228034973<br class="calibre9"/>
    }<br class="calibre9"/>
}</p>
<p class="noindent"><span epub:type="pagebreak" id="page_213"></span>It’s no surprise that that document had a negative sentiment score since it was previously scored this way. Another interesting thing this API can do is to score all of the documents inside as  one giant score. Basically, it gives the median sentiment value. Here is what that looks like.</p>
<p class="codelink"><a id="p213pro01" href="part0040_split_029.html#p213pro01a" class="calibre7">Click here to view code image</a></p>
<p class="pre">In [8]: whole_doc = ', '.join(map(str, output))<br class="calibre9"/>
<br class="calibre9"/>
In [9]: print(json.dumps(\<br class="calibre9"/>
comprehend.detect_sentiment(\<br class="calibre9"/>
Text=whole_doc, LanguageCode='en'), sort_keys=True, inden<br class="calibre9"/>
   ...: t=4))<br class="calibre9"/>
{<br class="calibre9"/>
    "ResponseMetadata": {<br class="calibre9"/>
        "HTTPHeaders": {<br class="calibre9"/>
            "connection": "keep-alive",<br class="calibre9"/>
            "content-length": "158",<br class="calibre9"/>
            "content-type": "application/x-amz-json-1.1",<br class="calibre9"/>
            "date": "Mon, 05 Mar 2018 05:46:12 GMT",<br class="calibre9"/>
            "x-amzn-requestid":\<br class="calibre9"/>
 "8296fa1a-2038-11e8-a5b9-b5b3e257e796"<br class="calibre9"/>
        },<br class="calibre9"/>
    "Sentiment": "MIXED",<br class="calibre9"/>
    "SentimentScore": {<br class="calibre9"/>
        "Mixed": 0.48351600766181946,<br class="calibre9"/>
        "Negative": 0.2868672013282776,<br class="calibre9"/>
        "Neutral": 0.12633098661899567,<br class="calibre9"/>
        "Positive": 0.1032857820391655<br class="calibre9"/>
    }<br class="calibre9"/>
}='en'), sort_keys=True, inden<br class="calibre9"/>
   ...: t=4))</p>
<p class="noindent">An interesting takeaway is that the AWS API has some hidden tricks up its sleeve and has a nuisance that is missing from the Azure API. In the previous Azure example, the Seaborn output showed that, indeed, there was a bimodal distribution with a minority of reviews liking the movie and a majority disliking the movie. The way AWS presents the results as “mixed” sums this up quite nicely.</p>
<p class="noindent">The only things left to do is to create a simple chalice app that will take the scored inputs that are written to Dynamo and serve them out. Here is what that looks like.</p>
<p class="codelink"><a id="p213pro02" href="part0040_split_030.html#p213pro02a" class="calibre7">Click here to view code image</a></p>
<p class="pre">from uuid import uuid4<br class="calibre9"/>
import logging<br class="calibre9"/>
import time<br class="calibre9"/>
<br class="calibre9"/>
from chalice import Chalice<br class="calibre9"/>
import boto3<br class="calibre9"/>
<span epub:type="pagebreak" id="page_214"></span>
from boto3.dynamodb.conditions import Key<br class="calibre9"/>
from pythonjsonlogger import jsonlogger<br class="calibre9"/>
<br class="calibre9"/>
#APP ENVIRONMENTAL VARIABLES<br class="calibre9"/>
REGION = "us-east-1"<br class="calibre9"/>
APP = "nlp-api"<br class="calibre9"/>
NLP_TABLE = "nlp-table"<br class="calibre9"/>
<br class="calibre9"/>
#intialize logging<br class="calibre9"/>
log = logging.getLogger("nlp-api")<br class="calibre9"/>
LOGHANDLER = logging.StreamHandler()  <br class="calibre9"/>
FORMMATTER = jsonlogger.JsonFormatter()<br class="calibre9"/>
LOGHANDLER.setFormatter(FORMMATTER)<br class="calibre9"/>
log.addHandler(LOGHANDLER)<br class="calibre9"/>
log.setLevel(logging.INFO)<br class="calibre9"/>
<br class="calibre9"/>
app = Chalice(app_name='nlp-api')<br class="calibre9"/>
app.debug = True<br class="calibre9"/>
<br class="calibre9"/>
def dynamodb_client():<br class="calibre9"/>
    """Create Dynamodb Client"""<br class="calibre9"/>
<br class="calibre9"/>
    extra_msg = {"region_name": REGION, "aws_service": "dynamodb"}<br class="calibre9"/>
    client = boto3.client('dynamodb', region_name=REGION)<br class="calibre9"/>
    log.info("dynamodb CLIENT connection initiated", extra=extra_msg)<br class="calibre9"/>
    return client<br class="calibre9"/>
<br class="calibre9"/>
def dynamodb_resource():<br class="calibre9"/>
    """Create Dynamodb Resource"""<br class="calibre9"/>
<br class="calibre9"/>
    extra_msg = {"region_name": REGION, "aws_service": "dynamodb"}<br class="calibre9"/>
    resource = boto3.resource('dynamodb', region_name=REGION)<br class="calibre9"/>
    log.info("dynamodb RESOURCE connection initiated",\<br class="calibre9"/>
          extra=extra_msg)<br class="calibre9"/>
    return resource<br class="calibre9"/>
<br class="calibre9"/>
def create_nlp_record(score):<br class="calibre9"/>
    """Creates nlp Table Record<br class="calibre9"/>
<br class="calibre9"/>
    """<br class="calibre9"/>
<br class="calibre9"/>
    db = dynamodb_resource()<br class="calibre9"/>
    pd_table = db.Table(NLP_TABLE)<br class="calibre9"/>
    guid = str(uuid4())<br class="calibre9"/>
    res = pd_table.put_item(<br class="calibre9"/>
        Item={<br class="calibre9"/>
            'guid': guid,<br class="calibre9"/>
            'UpdateTime' : time.asctime(),<br class="calibre9"/>
<span epub:type="pagebreak" id="page_215"></span>
            'nlp-score': score<br class="calibre9"/>
        }<br class="calibre9"/>
    )<br class="calibre9"/>
    extra_msg = {"region_name": REGION, "aws_service": "dynamodb"}<br class="calibre9"/>
    log.info(f"Created NLP Record with result{res}", extra=extra_msg)<br class="calibre9"/>
    return guid<br class="calibre9"/>
<br class="calibre9"/>
def query_nlp_record():<br class="calibre9"/>
    """Scans nlp table and retrieves all records"""<br class="calibre9"/>
    <br class="calibre9"/>
    db = dynamodb_resource()<br class="calibre9"/>
    extra_msg = {"region_name": REGION, "aws_service": "dynamodb",<br class="calibre9"/>
        "nlp_table":NLP_TABLE}<br class="calibre9"/>
    log.info(f"Table Scan of NLP table", extra=extra_msg)<br class="calibre9"/>
    pd_table = db.Table(NLP_TABLE)<br class="calibre9"/>
    res = pd_table.scan()<br class="calibre9"/>
    records = res['Items']<br class="calibre9"/>
    return records<br class="calibre9"/>
<br class="calibre9"/>
@app.route('/')<br class="calibre9"/>
def index():<br class="calibre9"/>
    """Default Route"""<br class="calibre9"/>
    <br class="calibre9"/>
    return {'hello': 'world'}<br class="calibre9"/>
<br class="calibre9"/>
@app.route("/nlp/list")<br class="calibre9"/>
def nlp_list():<br class="calibre9"/>
    """list nlp scores"""<br class="calibre9"/>
<br class="calibre9"/>
    extra_msg = {"region_name": REGION,<br class="calibre9"/>
        "aws_service": "dynamodb",<br class="calibre9"/>
        "route":"/nlp/list"}<br class="calibre9"/>
    log.info(f"List NLP Records via route", extra=extra_msg)    <br class="calibre9"/>
    res = query_nlp_record()<br class="calibre9"/>
    return res</p>
<h3 id="ch11lev11" class="calibre12">Summary</h3>
<p class="noindent">If data is the new oil, then UGC is the sand tar pits. Sand tar pits have been historically difficult to turn into production oil pipelines, but rising energy costs and advances in technology have allowed their mining to become feasible. Similarly, the AI APIs coming out of the “big three” cloud providers have created new technological breakthroughs in sifting through the “sandy data.” Also, prices for storage and computation have steadily dropped, making it much more feasible to convert UGC into an asset from which to extract extra value. Another innovation lowering the cost to process UGC is AI accelerators. Massive parallelization improvements by ASIC chips like TPUs, GPUs, and field-programmable graphic arrays (FPGAs) may make some of the scale issues discussed even less of an issue.</p>
<p class="noindent"><span epub:type="pagebreak" id="page_216"></span>This chapter showed many examples of how to extract value from these tar pits, but there are also real tradeoffs and dangers, as with the real sand tar pits. UGC to AI feedback loops can be tricked and exploited in ways that create consequences that are global in scale. Also, on a much more practical level, there are tradeoffs to consider when systems go live. As easy as the cloud and AI APIs make creating solutions, the real tradeoffs cannot be abstracted away, like UX, performance, and the business implications of implemented solutions.</p>
</body></html>
