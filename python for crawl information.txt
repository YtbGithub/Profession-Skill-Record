package
	1.crawl
		1.1 requests
		1.2 scrpy
		1.3 web driver
	2.parse
		2.1 beautifulSoup
		2.2 re
----------------------------------------------------------------------------------------------------------------------------------------------------------
1.1 requests
	request: r = requests.GET('...')
		GET: requests.get(url:str, headers:dict, params:dict) params:transmit parameters in get request.
		POST: requests.post(url:str, headers:dict, data:dict)
		and more PUT,DELETE,HEAD,OPTIONS those like it
	response: 
		text: r.text
		bytes(binary): r.content
		Image: from PIL improt Image,from io import bytesIO => Image.open(bytesIO(r.content))
		Json: r.json(), maybe need check current response status code. OR current response status code needed check
		raw response data: r.raw(), return an object, has function of read
	headers:
		headers_dict = {"key1":value1, "key2":value2}
		headers_tuple = (("key1", value1), ("key1", value2)) multiple values corresponding same key
		use, requests.post(url, data=json.dumps(headers_dict)), headers_dict was regarded as String Type transfer to service, be regarded as ...,被当作...
		use, requests.post(url, json=headers_dict), '''headers_dict was automatic coding'''


		
----------------------------------------------------------------------------------------------------------------------------------------------------------
1.2 scrpy
	scrapy startproject [project_name] [directory]
	scrapy genspider spider_name "指定允许爬取的域名"
	scrapy crawl spider_name

	如何用脚本方式启动scrapy：https://www.cnblogs.com/lawlietfans/p/7475742.html
	
	流程：
	1. spider 穿过 [spider middleware] 发送 request 到 engine(引擎)
	2. engine 转发 request 给 scheduler(调度器)
	3. scheduler 转发 request 给 engine
	4. engine 穿过 [download middleware] 转发 request 给 downloader
	5. downloader 下载之后,穿过 [download middleware] 发送 response 给 engine
	6. engine 拿到 response 发送给 spider
	7. spider 处理完之后 发送 request/item 给engine
	8. engine 如果接收到的是 request 则会调度给 scheduler
	   engine 如果接收到的是 items 则会调度给 piplines 进行持久化
	关于中间件：
		spider middleware：返回值不同引擎也会有不同的转发方向
			比如：
----------------------------------------------------------------------------------------------------------------------------------------------------------
1.3 web driver
----------------------------------------------------------------------------------------------------------------------------------------------------------
2.1 beautifulSoup
----------------------------------------------------------------------------------------------------------------------------------------------------------
2.2 re
----------------------------------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------------------------------